{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4c8b28c",
   "metadata": {},
   "source": [
    "Copyright (c) 2023 Graphcore Ltd. All rights reserved.\n",
    "\n",
    "# DFT dataset generation using PySCF IPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885d94eb",
   "metadata": {},
   "source": [
    "## Dependencies and configuration\n",
    "\n",
    "Install the JAX experimental for IPU (and addons).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b9ba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Update working directory to root directory of the repo.\n",
    "if len([d for d in os.listdir() if d.endswith(\".ipynb\")]) > 0:\n",
    "    os.chdir(os.getcwd() + \"/..\")\n",
    "print(\"Working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5faf299",
   "metadata": {},
   "source": [
    "Install `pyscf-ipu`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f54d5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -e \"..[ipu]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f8d675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16f39a33",
   "metadata": {},
   "source": [
    "# Download and preprocess GDB 11 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c260e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract GDB11 dataset.\n",
    "!wget -p -O ./gdb/gdb11.tgz https://zenodo.org/record/5172018/files/gdb11.tgz\\?download\\=1\n",
    "!tar -xvf ./gdb/gdb11.tgz --directory ./gdb/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350ad136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdb.sortgdb as sortgdb\n",
    "\n",
    "# Filter & sort GDB11 dataset (size 9).\n",
    "gdb_filename = \"./gdb/gdb11_size09.smi\"\n",
    "gdb_sorted = sortgdb.sort_gdb(gdb_filename, keep_only_atoms_count=9)\n",
    "# Save output as csv.\n",
    "out_filename = gdb_filename.replace(\".smi\", \"_sorted.csv\")\n",
    "gdb_sorted.to_csv(out_filename, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdf3730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530cbea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9da90c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PySCF IPU setup: use a single device per process.\n",
    "os.environ[\"JAX_IPU_DEVICE_COUNT\"] = \"1\"\n",
    "# JAX/XLA IPU compilation cache.\n",
    "os.environ['TF_POPLAR_FLAGS'] = \"\"\"\n",
    "  --executable_cache_path=/tmp/ipu-ef-cache\n",
    "\"\"\"\n",
    "\n",
    "# First import of JAX and TessellateIPU make take a few minutes...\n",
    "import jax\n",
    "import tessellate_ipu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa46c38d",
   "metadata": {},
   "source": [
    "# Create a DFT dataset using PySCF IPU\n",
    "\n",
    "In just a couple of Python lines, we can launch a background process building a DFT dataset using PySCF IPU.\n",
    "In the following example, we use only a single IPU. Multiple IPUs can be used by simply launching a collection of PySCF IPU processes instead of a single one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48596cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some PySCF parameters.\n",
    "\n",
    "# Number of conformers per molecule.\n",
    "num_conformers = 1000\n",
    "# Dataset name.\n",
    "dataset_name = \"notebook_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ea8a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class DFTProcess:\n",
    "    # Underlying process.\n",
    "    process: subprocess.Popen\n",
    "    # Path of the dataset generated.\n",
    "    path: str\n",
    "        \n",
    "    @property\n",
    "    def pid(self):\n",
    "        return self.process.pid\n",
    "    \n",
    "    def is_running(self):\n",
    "        return self.process.poll() == None\n",
    "        \n",
    "    def __del__(self):\n",
    "        print(\"Killing DFT dataset process with PID:\", self.process.pid)\n",
    "        self.process.kill()\n",
    "\n",
    "        \n",
    "def launch_dft_process() -> DFTProcess:\n",
    "    \"\"\"Launch an external PySCF IPU process building a DFT molecular dataset. \n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Make sure the root directory exists.\n",
    "        rootpath = f\"./data/generated/{dataset_name}/\"\n",
    "        os.makedirs(rootpath, exist_ok=True)\n",
    "        num_datasets = len(os.listdir(rootpath))\n",
    "        # Launch DFT process...\n",
    "        command_line = [\n",
    "            \"python\", \"density_functional_theory.py\",\n",
    "            \"-generate\",\n",
    "            \"-save\",\n",
    "            \"-fname\", dataset_name,\n",
    "            \"-level\",\"0\",\n",
    "            \"-plevel\",\"0\",\n",
    "            \"-num_conformers\", str(num_conformers),\n",
    "            \"-gdb\",\"9\",\n",
    "            \"-backend\",\"ipu\",\n",
    "            \"-float32\",\n",
    "        ]\n",
    "        raw_process = subprocess.Popen(command_line, env=os.environ.copy())\n",
    "        print(\"Launching DFT dataset process with PID\", raw_process.pid, \"... Please wait...\")\n",
    "        # Wait the new directory is created...\n",
    "        while len(os.listdir(rootpath)) == num_datasets or raw_process.poll() != None:\n",
    "            time.sleep(1.0)\n",
    "        # Failure while launching?\n",
    "        if raw_process.poll() != None:\n",
    "            raise RuntimeError(\"Error while launching PySCF IPU process...\")\n",
    "        # Find the dataset path (sorted by date).\n",
    "        paths = sorted(os.listdir(rootpath), key=lambda x: os.path.getmtime(rootpath + x))\n",
    "        filename = os.path.join(rootpath, paths[-1], \"data.csv\")\n",
    "        return DFTProcess(raw_process, filename)\n",
    "    except Exception as e:\n",
    "        # Capture any issue, and kill the process in this case.\n",
    "        raw_process.kill()\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbfe415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launching an external PySCF IPU process\n",
    "dft_process = launch_dft_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894a97a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PySCF IPU DFT computation on-going. Dataset saved in:\", dft_process.path)\n",
    "dft_process.is_running()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b192ca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want to stop the process?\n",
    "# dft_process.process.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a62d0e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0ec0c9d",
   "metadata": {},
   "source": [
    "# Loading & visualizing generated data\n",
    "\n",
    "As the dataset is being created in the background, we can load the data which has been already generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d778133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfd2293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output DFT dataset is a compressed CSV file.\n",
    "# NOTE: it may take a couple of minutes before the file is generated.\n",
    "df = pd.read_csv(dft_process.path, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e816e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd76867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HLgap data.\n",
    "df[\"hlgap\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e50efa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
